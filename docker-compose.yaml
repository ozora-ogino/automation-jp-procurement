services:
  postgres:
    image: pgvector/pgvector:pg15
    container_name: airflow_postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - ./docker_volumes/postgres_data:/var/lib/postgresql/data
      - ./sql/setup_db.sql:/docker-entrypoint-initdb.d/setup_db.sql
    ports:
      - "${POSTGRES_PORT}:5432"
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "${POSTGRES_USER}" ]
      interval: 10s
      retries: 5
      start_period: 5s

  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow_webserver
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: ${AIRFLOW_EXECUTOR}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: ${AIRFLOW_DAGS_PAUSED_AT_CREATION}
      AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW_LOAD_EXAMPLES}
      AIRFLOW__API__AUTH_BACKENDS: "airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session"
      AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: "true"
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}
      DASHBOARD_URL: ${DASHBOARD_URL:-http://localhost:3032}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      NJSS_USERNAME: ${NJSS_USERNAME}
      NJSS_PASSWORD: ${NJSS_PASSWORD}
    volumes:
      - ./dags:/opt/airflow/dags
      - ./docker_volumes/logs:/opt/airflow/logs
      - ./docker_volumes/config:/opt/airflow/config
      - ./docker_volumes/plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/csv_data
      - ./requirements.txt:/opt/airflow/requirements.txt:ro
    ports:
      - "${AIRFLOW_WEBSERVER_PORT}:8080"
    healthcheck:
      test: [ "CMD", "curl", "--fail", "http://localhost:8080/health" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    command: >
      bash -c "
        if [ -f /opt/airflow/requirements.txt ]; then
          pip install --no-cache-dir -r /opt/airflow/requirements.txt
        fi &&
        airflow db migrate &&
        airflow users create --username ${AIRFLOW_ADMIN_USERNAME} --password ${AIRFLOW_ADMIN_PASSWORD} --firstname ${AIRFLOW_ADMIN_FIRSTNAME} --lastname ${AIRFLOW_ADMIN_LASTNAME} --role Admin --email ${AIRFLOW_ADMIN_EMAIL} || true &&
        airflow webserver
      "

  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    container_name: procurement_api
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
    ports:
      - "8002:8000"
    volumes:
      - ./api/src:/app/src
    healthcheck:
      test: [ "CMD", "curl", "--fail", "http://localhost:8000/health" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  web:
    build:
      context: ./web
      dockerfile: Dockerfile
    container_name: procurement_dashboard
    restart: unless-stopped
    depends_on:
      api:
        condition: service_started
    environment:
      BACKEND_URL: ${BACKEND_URL}
    ports:
      - "3032:80"
    healthcheck:
      test: [ "CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:80/" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow_scheduler
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: ${AIRFLOW_EXECUTOR}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: ${AIRFLOW_DAGS_PAUSED_AT_CREATION}
      AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW_LOAD_EXAMPLES}
      AIRFLOW__API__AUTH_BACKENDS: "airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session"
      AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: "true"
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}
      DASHBOARD_URL: ${DASHBOARD_URL:-http://localhost:3032}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      NJSS_USERNAME: ${NJSS_USERNAME}
      NJSS_PASSWORD: ${NJSS_PASSWORD}
    volumes:
      - ./dags:/opt/airflow/dags
      - ./docker_volumes/logs:/opt/airflow/logs
      - ./docker_volumes/config:/opt/airflow/config
      - ./docker_volumes/plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/csv_data
      - ./requirements.txt:/opt/airflow/requirements.txt:ro
    healthcheck:
      test: [ "CMD", "curl", "--fail", "http://localhost:8974/health" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    command: >
      bash -c "
        if [ -f /opt/airflow/requirements.txt ]; then
          pip install --no-cache-dir -r /opt/airflow/requirements.txt
        fi &&
        airflow scheduler
      "
